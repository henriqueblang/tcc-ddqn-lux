{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading environment football failed: No module named 'gfootball'\n"
     ]
    }
   ],
   "source": [
    "from kaggle_environments import make\n",
    "from lux.game import Game\n",
    "from lux.game_map import Cell, RESOURCE_TYPES, Position\n",
    "from lux.game_objects import Unit\n",
    "from lux.constants import Constants\n",
    "from lux.game_constants import GAME_CONSTANTS\n",
    "from lux import annotate\n",
    "import math\n",
    "import sys\n",
    "import numpy as np\n",
    "import random\n",
    "from IPython.display import clear_output \n",
    "from lux.game import Game\n",
    "from lux.game_map import Cell, RESOURCE_TYPES\n",
    "from lux.constants import Constants\n",
    "from lux.game_constants import GAME_CONSTANTS\n",
    "from lux import annotate\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "from collections import deque\n",
    "import random\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_inputs(game_state):\n",
    "    # The shape of the map\n",
    "    w,h = game_state.map.width, game_state.map.height\n",
    "    # The map of ressources\n",
    "    M = [ [0  if game_state.map.map[j][i].resource==None else game_state.map.map[j][i].resource.amount for i in range(w)]  for j in range(h)]\n",
    "    \n",
    "    M = np.array(M).reshape((h,w,1))\n",
    "    \n",
    "    # The map of units features\n",
    "    U_player = [ [[0,0,0,0,0] for i in range(w)]  for j in range(h)]    \n",
    "    units = game_state.players[0].units\n",
    "    for i in units:\n",
    "        U_player[i.pos.y][i.pos.x] = [i.type,i.cooldown,i.cargo.wood,i.cargo.coal,i.cargo.uranium]\n",
    "    U_player = np.array(U_player)\n",
    "    \n",
    "    U_opponent = [ [[0,0,0,0,0] for i in range(w)]  for j in range(h)]\n",
    "    units = game_state.players[1].units\n",
    "    for i in units:\n",
    "        U_opponent[i.pos.y][i.pos.x] = [i.type,i.cooldown,i.cargo.wood,i.cargo.coal,i.cargo.uranium]\n",
    "\n",
    "    U_opponent = np.array(U_opponent)\n",
    "    \n",
    "    # The map of cities featrues\n",
    "    e = game_state.players[0].cities\n",
    "    C_player = [ [[0,0,0] for i in range(w)]  for j in range(h)]\n",
    "    for k in e:\n",
    "        citytiles = e[k].citytiles\n",
    "        for i in citytiles:\n",
    "            C_player[i.pos.y][i.pos.x] = [i.cooldown,e[k].fuel,e[k].light_upkeep]\n",
    "    C_player = np.array(C_player)\n",
    "\n",
    "    e = game_state.players[1].cities\n",
    "    C_opponent = [ [[0,0,0] for i in range(w)]  for j in range(h)]\n",
    "    for k in e:\n",
    "        citytiles = e[k].citytiles\n",
    "        for i in citytiles:\n",
    "            C_opponent[i.pos.y][i.pos.x] = [i.cooldown,e[k].fuel,e[k].light_upkeep]\n",
    "    C_opponent = np.array(C_opponent)\n",
    "    \n",
    "    # stacking all in one array\n",
    "    E = np.dstack([M,U_opponent,U_player,C_opponent,C_player])\n",
    "    return E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(s):\n",
    "    inputs = keras.Input(shape=(s,s,17),name = 'TheGameMap')\n",
    "    f = layers.Flatten()(inputs)   \n",
    "    h,w= s,s\n",
    "    f = layers.Dense(w*h,activation = \"sigmoid\")(f)\n",
    "    f = layers.Reshape((h,w,-1))(f)\n",
    "    units = layers.Dense(6,activation = \"softmax\",name = \"Units_actions\")(f)\n",
    "    cities = layers.Dense(2,activation = \"sigmoid\",name = \"Cities_actions\")(f)\n",
    "    output = layers.Concatenate()([units,cities])\n",
    "    model = keras.Model(inputs = inputs, outputs = output)\n",
    "    #model.compile(loss='mse', optimizer=\"adam\")\n",
    "    model.compile(loss='mse', optimizer=\"nadam\")\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " TheGameMap (InputLayer)        [(None, 12, 12, 17)  0           []                               \n",
      "                                ]                                                                 \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 2448)         0           ['TheGameMap[0][0]']             \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 144)          352656      ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      " reshape (Reshape)              (None, 12, 12, 1)    0           ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " Units_actions (Dense)          (None, 12, 12, 6)    12          ['reshape[0][0]']                \n",
      "                                                                                                  \n",
      " Cities_actions (Dense)         (None, 12, 12, 2)    4           ['reshape[0][0]']                \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 12, 12, 8)    0           ['Units_actions[0][0]',          \n",
      "                                                                  'Cities_actions[0][0]']         \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 352,672\n",
      "Trainable params: 352,672\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = get_model(12)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_direction(action):\n",
    "    return \"csnwe\"[action] if action < 5 else None "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unit_future_position(unit, direction):\n",
    "    to_x = unit.pos.x\n",
    "    to_y = unit.pos.y\n",
    "\n",
    "    if direction == \"e\":\n",
    "        to_x += 1\n",
    "    elif direction == \"s\":\n",
    "        to_y += 1\n",
    "    elif direction == \"w\":\n",
    "        to_x -= 1\n",
    "    elif direction == \"n\":\n",
    "        to_y -= 1\n",
    "        \n",
    "    return to_x, to_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_unit_action_valid(unit, option, actions, player, opponent):\n",
    "    height, width = game_state.map.width, game_state.map.height\n",
    "    \n",
    "    if not unit.can_act():\n",
    "        return False\n",
    "    \n",
    "    # if option == move:\n",
    "    if option < 5:\n",
    "        to_x, to_y = get_unit_future_position(unit, get_direction(option))\n",
    "\n",
    "        # Out of bond\n",
    "        if to_x < 0 or to_x >= width or to_y < 0 or to_y >= height:\n",
    "            return False\n",
    "\n",
    "        to_cell = game_state.map.get_cell(to_x, to_y)\n",
    "        to_citytile = to_cell.citytile\n",
    "\n",
    "        # Not citytile and cell already has unit\n",
    "        if to_citytile is None:\n",
    "            has_player_unit = to_cell.has_player_unit(player)\n",
    "            has_opponent_unit = to_cell.has_player_unit(opponent)\n",
    "            \n",
    "            if has_player_unit or has_opponent_unit:\n",
    "                return False\n",
    "\n",
    "            for action in actions:\n",
    "                # Move action string is \"m {} {}\".format(self.id, dir)\n",
    "                action = action.split(\" \")\n",
    "\n",
    "                if action[0] != \"m\":\n",
    "                    continue\n",
    "\n",
    "                _, player_unit_id, direction = action\n",
    "\n",
    "                player_unit_to_x = player_unit_to_y = None\n",
    "                for player_unit in player.units:\n",
    "                    if player_unit.id != player_unit_id:\n",
    "                        continue\n",
    "\n",
    "                    player_unit_to_x, player_unit_to_y = get_unit_future_position(player_unit, direction)\n",
    "                    break\n",
    "\n",
    "                if player_unit_to_x is None or player_unit_to_y is None:\n",
    "                    continue\n",
    "\n",
    "                if to_x == player_unit_to_x and to_y == player_unit_to_y:\n",
    "                    return False\n",
    "                    \n",
    "        # Opponent citytile\n",
    "        elif to_citytile.team == opponent.team:\n",
    "            return False\n",
    "    #elif option == build_city:\n",
    "    elif option == 5:\n",
    "        if not unit.can_build(game_state.map):\n",
    "            return False\n",
    "    else: return False\n",
    "    '''elif option == pillage:\n",
    "        to_cell = get_cell(to_x, to_y)\n",
    "\n",
    "        # Not road\n",
    "        if to_cell.road == 0:\n",
    "            return False'''\n",
    "\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_city_tile_action_valid(city_tile, action, player):\n",
    "    if not city_tile.can_act():\n",
    "        return False\n",
    "    \n",
    "    #if action == research:\n",
    "    if action == 6:\n",
    "        pass\n",
    "    #elif action == build_worker or action == build_cart:\n",
    "    elif action == 7:\n",
    "        owned_units = len(player.units)\n",
    "        owned_city_tiles = 0\n",
    "        \n",
    "        for city in player.cities.values():\n",
    "            owned_city_tiles += len(city.citytiles)\n",
    "\n",
    "        if owned_units >= owned_city_tiles:\n",
    "            return False\n",
    "    else: return False\n",
    "        \n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_unit_valid_action(unit, options, actions, player, opponent, i=1):\n",
    "    if i == len(options):\n",
    "        return -1\n",
    "    \n",
    "    option = np.argsort(options)[-i]\n",
    "    \n",
    "    if is_unit_action_valid(unit, option, actions, player, opponent):\n",
    "        return option\n",
    "    \n",
    "    return get_best_unit_valid_action(unit, options, actions, player, opponent, i + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_city_tile_valid_action(city_tile, options, player, i=1):\n",
    "    if i == len(options):\n",
    "        return -1\n",
    "    \n",
    "    option = np.argsort(options)[-i]\n",
    "    \n",
    "    if is_city_tile_action_valid(city_tile, option, player):\n",
    "        return option\n",
    "    \n",
    "    return get_best_city_tile_valid_action(city_tile, options, player, i + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction_actions(y_A, y_B, player, opponent):\n",
    "    actions = []\n",
    "    best_options = np.zeros((game_state.map.width, game_state.map.height), dtype=int)\n",
    "\n",
    "    for unit in player.units:\n",
    "        unit_y, unit_x = unit.pos.y, unit.pos.x\n",
    "\n",
    "        options = y_A[unit_y][unit_x] + y_B[unit_y][unit_x]\n",
    "        \n",
    "        best_option = get_best_unit_valid_action(unit, options, actions, player, opponent)\n",
    "        best_options[unit_y, unit_x] = best_option\n",
    "\n",
    "        if -1 < best_option < 5:\n",
    "            actions.append(unit.move(get_direction(best_option)))\n",
    "        elif best_option == 5:\n",
    "            actions.append(unit.build_city())\n",
    "            \n",
    "    for city in player.cities.values():\n",
    "        for city_tile in city.citytiles:\n",
    "            city_tile_y, city_tile_x = city_tile.pos.y, city_tile.pos.x\n",
    "            \n",
    "            options = y_A[city_tile_y][city_tile_x] + y_B[city_tile_y][city_tile_x]\n",
    "            \n",
    "            best_option = get_best_city_tile_valid_action(city_tile, options, player)\n",
    "            best_options[city_tile_y, city_tile_x] = best_option\n",
    "        \n",
    "            if best_option == 6:\n",
    "                actions.append(city_tile.research())\n",
    "            elif best_option == 7:\n",
    "                actions.append(city_tile.build_worker())\n",
    "    \n",
    "    return actions, best_options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "Last_State = {}\n",
    "learning_rate = 0.01\n",
    "gamma = 0.95\n",
    "epsilon = 1.0\n",
    "epsilon_final = 0.01\n",
    "epsilon_decay = 0.995\n",
    "game_state = None\n",
    "model = None\n",
    "last_reward = 0\n",
    "W = 0\n",
    "def agent(observation, configuration):\n",
    "    global game_state, epsilon, model_A, model_B, last_reward, W\n",
    "    \n",
    "    ### Do not edit ###\n",
    "    if observation[\"step\"] == 0:\n",
    "        game_state = Game()\n",
    "        game_state._initialize(observation[\"updates\"])\n",
    "        game_state._update(observation[\"updates\"][2:])\n",
    "        game_state.id = observation.player\n",
    "    else:\n",
    "        game_state._update(observation[\"updates\"])\n",
    "    \n",
    "\n",
    "    ### AI Code goes down here! ### \n",
    "    player = game_state.players[observation.player]\n",
    "    opponent = game_state.players[(observation.player + 1) % 2]\n",
    "    width, height = game_state.map.width, game_state.map.height\n",
    "\n",
    "    # Get Prediction of actions\n",
    "    x = get_inputs(game_state)\n",
    "    y_A = model_A.predict(np.asarray([x]))[0]\n",
    "    y_B = model_B.predict(np.asarray([x]))[0]\n",
    "    \n",
    "    if random.random() < epsilon:\n",
    "        y_A = np.random.rand(*y_A.shape)\n",
    "        y_B = np.random.rand(*y_B.shape)\n",
    "        \n",
    "    print(\"eps \",epsilon,end= \" | \") \n",
    "    actions_A, option_A = get_prediction_actions(y_A, y_A, player, opponent)\n",
    "    actions_B, option_B = get_prediction_actions(y_B, y_B, player, opponent)\n",
    "    \n",
    "    print(\"Reward: \", observation[\"reward\"])\n",
    "    \n",
    "    is_model_A = random.random() < 0.5\n",
    "    \n",
    "    if observation.player in Last_State:\n",
    "        _x, _y_A, _y_B, _player, _option_A, _option_B = Last_State[observation.player]\n",
    "        state, next_state, reward = _x, x, observation[\"reward\"]\n",
    "        \n",
    "        # Reward \n",
    "        if reward > last_reward: \n",
    "            r = 1\n",
    "        elif reward < last_reward: \n",
    "            r = -1\n",
    "        else: \n",
    "            r = 0\n",
    "        \n",
    "        # Double Q-learning update\n",
    "        \n",
    "        if is_model_A:\n",
    "            model = model_A\n",
    "            _y = _y_A\n",
    "            y = y_B\n",
    "            _option = _option_A\n",
    "            option = option_A\n",
    "        else:\n",
    "            model = model_B\n",
    "            _y = _y_B\n",
    "            y = y_A\n",
    "            _option = _option_B\n",
    "            option = option_B\n",
    " \n",
    "        for i in _player.units:\n",
    "            Q1 = _y[i.pos.y, i.pos.x][_option[i.pos.y, i.pos.x]]\n",
    "            Q2 = y[i.pos.y, i.pos.x][option[i.pos.y, i.pos.x]]\n",
    "            _y[i.pos.y, i.pos.x][_option[i.pos.y, i.pos.x]] += learning_rate * (r + gamma * Q2 - Q1)\n",
    "        \n",
    "        states = [state]\n",
    "        _y_ = [_y]\n",
    "        \n",
    "        model.fit(np.asarray(states), np.asarray(_y_), epochs=1, verbose=1)\n",
    "        \n",
    "        if epsilon > epsilon_final:\n",
    "            epsilon *= epsilon_decay\n",
    "            \n",
    "    Last_State[observation.player] = [x, y_A, y_B, player, option_A, option_B]\n",
    "    last_reward = observation[\"reward\"]\n",
    "    \n",
    "    return actions_A if is_model_A else actions_B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Episode 9 ===\n",
      "eps  0.2 | Reward:  0\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.2753e-07\n",
      "eps  0.199 | Reward:  10001\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.5327e-07\n",
      "eps  0.19800500000000001 | Reward:  10001\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.1803e-08\n",
      "eps  0.197014975 | Reward:  10001\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.3546e-08\n",
      "eps  0.19602990012500002 | Reward:  10001\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.1615\n",
      "eps  0.19504975062437502 | Reward:  10001\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 2.7509e-04\n",
      "eps  0.19407450187125314 | Reward:  10001\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.2367e-08\n",
      "eps  0.19310412936189686 | Reward:  20001\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.3905e-07\n",
      "eps  0.19213860871508737 | Reward:  20001\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.0971e-05\n",
      "eps  0.19117791567151193 | Reward:  20001\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.1969e-05\n",
      "eps  0.19022202609315436 | Reward:  20001\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 8.7316e-11\n",
      "eps  0.18927091596268858 | Reward:  20002\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 2.7581e-07\n",
      "eps  0.18832456138287512 | Reward:  20002\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.1697\n",
      "eps  0.18738293857596075 | Reward:  20002\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.0460e-08\n",
      "eps  0.18644602388308096 | Reward:  20002\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.1695\n",
      "eps  0.18551379376366556 | Reward:  20002\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.0991e-04\n",
      "eps  0.18458622479484724 | Reward:  20002\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.4972e-08\n",
      "eps  0.183663293670873 | Reward:  20002\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.3016e-09\n",
      "eps  0.18274497720251864 | Reward:  20002\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.1786\n",
      "eps  0.18183125231650604 | Reward:  20002\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 3.0401e-07\n",
      "eps  0.18092209605492351 | Reward:  20002\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 5.8498e-09\n",
      "eps  0.1800174855746489 | Reward:  20002\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.1674\n",
      "eps  0.17911739814677563 | Reward:  20002\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.1571\n",
      "eps  0.17822181115604174 | Reward:  20002\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.1782\n",
      "eps  0.17733070210026153 | Reward:  20002\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 5.4080e-05\n",
      "eps  0.17644404858976023 | Reward:  20002\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.2888e-08\n",
      "eps  0.17556182834681144 | Reward:  20002\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 5.8045e-06\n",
      "eps  0.1746840192050774 | Reward:  20002\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.0513e-08\n",
      "eps  0.173810599109052 | Reward:  20002\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.2278e-08\n",
      "eps  0.17294154611350673 | Reward:  20002\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 3.9137e-08\n",
      "eps  0.1720768383829392 | Reward:  20002\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 6.1195e-05\n",
      "eps  0.1712164541910245 | Reward:  20002\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 4.1407e-05\n",
      "eps  0.17036037192006936 | Reward:  20002\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 6.5108e-11\n",
      "eps  0.16950857006046902 | Reward:  20002\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 1.9776e-09\n",
      "eps  0.16866102721016668 | Reward:  20002\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 2.2726e-06\n",
      "eps  0.16781772207411585 | Reward:  20002\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.1550\n",
      "eps  0.16697863346374528 | Reward:  20002\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.8196e-10\n",
      "eps  0.16614374029642656 | Reward:  20002\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.1977e-09\n",
      "eps  0.16531302159494443 | Reward:  20002\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.6581e-08\n",
      "eps  0.16448645648696972 | Reward:  20002\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 9.4409e-09\n",
      "eps  0.16366402420453488 | Reward:  20002\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 8.5502e-09\n",
      "eps  0.1628457040835122 | Reward:  20002\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.0987e-09\n",
      "eps  0.16203147556309463 | Reward:  20002\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 9.1796e-09\n",
      "eps  0.16122131818527916 | Reward:  30002\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.1609\n",
      "eps  0.16041521159435276 | Reward:  30003\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 5.3262e-05\n",
      "eps  0.159613135536381 | Reward:  30003\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.2096e-08\n",
      "eps  0.15881506985869911 | Reward:  30003\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.1724\n",
      "eps  0.15802099450940563 | Reward:  30003\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 2.1507e-08\n",
      "eps  0.1572308895368586 | Reward:  30003\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.2103e-08\n",
      "eps  0.1564447350891743 | Reward:  30003\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 3.2877e-08\n",
      "eps  0.15566251141372844 | Reward:  30003\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 2.0433e-08\n",
      "eps  0.1548841988566598 | Reward:  30003\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.1708\n",
      "eps  0.1541097778623765 | Reward:  30003\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 3.2772e-08\n",
      "eps  0.15333922897306462 | Reward:  30003\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 2.3036e-08\n",
      "eps  0.1525725328281993 | Reward:  30003\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 2.5064e-06\n",
      "eps  0.1518096701640583 | Reward:  30003\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 8.4531e-06\n",
      "eps  0.151050621813238 | Reward:  30003\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.1675\n",
      "eps  0.15029536870417182 | Reward:  30003\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 2.5880e-08\n",
      "eps  0.14954389186065095 | Reward:  30003\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 2.4353e-08\n",
      "eps  0.1487961724013477 | Reward:  30003\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 6.0076e-08\n",
      "eps  0.14805219153934096 | Reward:  30003\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.3434e-08\n",
      "eps  0.14731193058164427 | Reward:  30003\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 3.2182e-08\n",
      "eps  0.14657537092873604 | Reward:  30003\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 3.9492e-08\n",
      "eps  0.14584249407409236 | Reward:  30003\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1722\n",
      "eps  0.1451132816037219 | Reward:  30003\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 5.6315e-08\n",
      "eps  0.1443877151957033 | Reward:  30003\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1616\n",
      "eps  0.14366577661972477 | Reward:  30003\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.3617e-08\n",
      "eps  0.14294744773662615 | Reward:  30003\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.1744\n",
      "eps  0.14223271049794303 | Reward:  30003\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.9797e-08\n",
      "eps  0.14152154694545332 | Reward:  30003\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 2.6707e-08\n",
      "eps  0.14081393921072605 | Reward:  30003\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.1109e-08\n",
      "eps  0.1401098695146724 | Reward:  30001\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 9.3388e-08\n",
      "eps  0.13940932016709906 | Reward:  30001\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 2.2359e-09\n",
      "eps  0.13871227356626356 | Reward:  30001\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1669\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eps  0.13801871219843223 | Reward:  30002\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 2.4242e-07\n",
      "eps  0.13732861863744006 | Reward:  30001\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 1.4823e-07\n",
      "eps  0.13664197554425286 | Reward:  30001\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 2.4281e-09\n",
      "eps  0.1359587656665316 | Reward:  30000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0000e+00\n",
      "eps  0.13527897183819892 | Reward:  30001\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 8.0416e-08\n",
      "eps  0.13460257697900793 | Reward:  30000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0000e+00\n",
      "eps  0.13392956409411289 | Reward:  30000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.5423e-09\n",
      "eps  0.1332599162736423 | Reward:  30001\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 8.1280e-08\n",
      "eps  0.1325936166922741 | Reward:  30001\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 2.0815e-11\n",
      "eps  0.13193064860881273 | Reward:  30001\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 8.0674e-09\n",
      "eps  0.13127099536576867 | Reward:  30002\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.3351e-07\n",
      "eps  0.13061464038893983 | Reward:  30002\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 1.0612e-08\n",
      "eps  0.12996156718699514 | Reward:  30002\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.2688e-08\n",
      "eps  0.12931175935106015 | Reward:  30002\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.1122e-08\n",
      "eps  0.12866520055430486 | Reward:  30002\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.5815e-08\n",
      "eps  0.12802187455153333 | Reward:  30002\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 2.5322e-08\n",
      "eps  0.12738176517877567 | Reward:  30002\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.3691e-08\n",
      "eps  0.1267448563528818 | Reward:  30002\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 2.4401e-08\n",
      "eps  0.12611113207111738 | Reward:  30002\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.9905e-08\n",
      "eps  0.1254805764107618 | Reward:  30002\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.7176e-08\n",
      "eps  0.12485317352870799 | Reward:  30003\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 3.8047e-07\n",
      "eps  0.12422890766106445 | Reward:  30003\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 2.4868e-08\n",
      "eps  0.12360776312275913 | Reward:  30003\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 1.8803e-08\n",
      "eps  0.12298972430714533 | Reward:  30003\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 8.1940e-09\n",
      "eps  0.1223747756856096 | Reward:  30003\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.3437e-08\n",
      "eps  0.12176290180718155 | Reward:  30003\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 2.6909e-08\n",
      "eps  0.12115408729814564 | Reward:  30003\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.5471e-08\n",
      "eps  0.12054831686165492 | Reward:  30003\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 7.7196e-06\n",
      "eps  0.11994557527734664 | Reward:  30003\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 7.3201e-06\n",
      "eps  0.11934584740095991 | Reward:  30003\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 2.8836e-08\n",
      "eps  0.11874911816395511 | Reward:  40003\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 4.5035e-07\n",
      "eps  0.11815537257313534 | Reward:  40003\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 5.2718e-05\n",
      "eps  0.11756459571026966 | Reward:  40003\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 2.2252e-08\n",
      "eps  0.1169767727317183 | Reward:  40003\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 2.8932e-08\n",
      "eps  0.1163918888680597 | Reward:  40003\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 2.1728e-08\n",
      "eps  0.11580992942371941 | Reward:  40003\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 3.4602e-08\n",
      "eps  0.11523087977660082 | Reward:  40003\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.3895e-08\n",
      "eps  0.11465472537771781 | Reward:  30004\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.1677\n",
      "eps  0.11408145175082922 | Reward:  30004\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 3.0018e-08\n",
      "eps  0.11351104449207507 | Reward:  30003\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.1570\n",
      "eps  0.11294348926961469 | Reward:  30003\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 1.1045e-09\n",
      "eps  0.11237877182326661 | Reward:  30003\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1636\n",
      "eps  0.11181687796415028 | Reward:  30003\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 5.0409e-05\n",
      "eps  0.11125779357432954 | Reward:  30002\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.1686\n",
      "eps  0.11070150460645789 | Reward:  30002\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 7.6917e-06\n",
      "eps  0.1101479970834256 | Reward:  30002\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 1.4775e-08\n",
      "eps  0.10959725709800847 | Reward:  30002\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 1.3341e-09\n",
      "eps  0.10904927081251842 | Reward:  30003\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 2.2582e-07\n",
      "eps  0.10850402445845582 | Reward:  30003\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 3.4689e-08\n",
      "eps  0.10796150433616354 | Reward:  50003\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 3.4255e-07\n",
      "eps  0.10742169681448273 | Reward:  50005\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1789\n",
      "eps  0.10688458833041031 | Reward:  50005\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 2.9039e-07\n",
      "eps  0.10635016538875826 | Reward:  50005\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 3.0084e-08\n",
      "eps  0.10581841456181447 | Reward:  50005\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.5624e-08\n",
      "eps  0.1052893224890054 | Reward:  50005\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 9.0049e-07\n",
      "eps  0.10476287587656037 | Reward:  50005\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.1705\n",
      "eps  0.10423906149717757 | Reward:  50005\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 1.4355e-08\n",
      "eps  0.10371786618969168 | Reward:  50005\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 2.3183e-08\n",
      "eps  0.10319927685874322 | Reward:  50005\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.6653e-08\n",
      "eps  0.10268328047444951 | Reward:  50005\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 2.5296e-08\n",
      "eps  0.10216986407207726 | Reward:  50005\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 4.7305e-08\n",
      "eps  0.10165901475171688 | Reward:  50005\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 3.6582e-08\n",
      "eps  0.10115071967795829 | Reward:  50005\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 2.2828e-08\n",
      "eps  0.10064496607956849 | Reward:  50005\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.1640\n",
      "eps  0.10014174124917065 | Reward:  50005\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 5.0546e-08\n",
      "eps  0.09964103254292479 | Reward:  60005\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 4.4393e-07\n",
      "eps  0.09914282738021017 | Reward:  60005\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 3.4775e-08\n",
      "eps  0.09864711324330912 | Reward:  60006\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.9042e-07\n",
      "eps  0.09815387767709258 | Reward:  60006\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 2.1439e-08\n",
      "eps  0.09766310828870711 | Reward:  60006\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 8.0512e-06\n",
      "eps  0.09717479274726358 | Reward:  60006\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 5.0236e-07\n",
      "eps  0.09668891878352726 | Reward:  60006\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 3.6135e-08\n",
      "eps  0.09620547418960962 | Reward:  60006\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4.4637e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eps  0.09572444681866157 | Reward:  60006\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 8.8296e-05\n",
      "eps  0.09524582458456826 | Reward:  60006\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 2.4640e-08\n",
      "eps  0.09476959546164541 | Reward:  60006\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 3.6724e-08\n",
      "eps  0.09429574748433718 | Reward:  60006\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7092e-08\n",
      "eps  0.09382426874691549 | Reward:  60006\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 3.1172e-08\n",
      "eps  0.09335514740318092 | Reward:  60006\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.6927e-08\n",
      "eps  0.09288837166616501 | Reward:  60006\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.9790e-08\n",
      "eps  0.09242392980783419 | Reward:  60006\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.2265e-05\n",
      "eps  0.09196181015879502 | Reward:  50006\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 7.5429e-07\n",
      "eps  0.09150200110800105 | Reward:  50006\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 3.9833e-08\n",
      "eps  0.09104449110246104 | Reward:  50006\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 1.4227e-08\n",
      "eps  0.09058926864694875 | Reward:  50006\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.5196e-08\n",
      "eps  0.090136322303714 | Reward:  50006\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 5.4894e-08\n",
      "eps  0.08968564069219544 | Reward:  50006\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.1601\n",
      "eps  0.08923721248873447 | Reward:  50006\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 2.8281e-08\n",
      "eps  0.08879102642629079 | Reward:  50006\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 2.0265e-08\n",
      "eps  0.08834707129415934 | Reward:  50006\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 9.7215e-08\n",
      "eps  0.08790533593768854 | Reward:  60006\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 5.5956e-07\n",
      "eps  0.0874658092580001 | Reward:  60006\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 3.1562e-08\n",
      "eps  0.0870284802117101 | Reward:  60006\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 4.3498e-08\n",
      "eps  0.08659333781065155 | Reward:  60006\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 4.5454e-08\n",
      "eps  0.0861603711215983 | Reward:  60006\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 4.0934e-08\n",
      "eps  0.0857295692659903 | Reward:  60006\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 4.9757e-08\n",
      "eps  0.08530092141966035 | Reward:  60006\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 6.4334e-08\n",
      "eps  0.08487441681256205 | Reward:  60006\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.1672\n",
      "eps  0.08445004472849925 | Reward:  60006\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.4040e-04\n",
      "eps  0.08402779450485676 | Reward:  60006\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.3996e-08\n",
      "eps  0.08360765553233247 | Reward:  60006\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 3.1580e-08\n",
      "eps  0.0831896172546708 | Reward:  60006\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 2.6648e-08\n",
      "eps  0.08277366916839746 | Reward:  60006\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.1716\n",
      "eps  0.08235980082255547 | Reward:  60006\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 4.5316e-08\n",
      "eps  0.08194800181844268 | Reward:  60006\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 5.1680e-08\n",
      "eps  0.08153826180935046 | Reward:  60006\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 5.5060e-08\n",
      "eps  0.08113057050030371 | Reward:  60006\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 4.4308e-08\n",
      "eps  0.0807249176478022 | Reward:  60006\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.1131e-07\n",
      "eps  0.08032129305956318 | Reward:  60006\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.1603\n",
      "eps  0.07991968659426536 | Reward:  60006\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 5.2945e-05\n",
      "eps  0.07952008816129404 | Reward:  60006\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 4.1131e-08\n",
      "eps  0.07912248772048756 | Reward:  60006\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 4.1424e-08\n",
      "eps  0.07872687528188513 | Reward:  60006\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 5.1111e-06\n",
      "eps  0.0783332409054757 | Reward:  70006\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 8.6750e-07\n",
      "eps  0.07794157470094833 | Reward:  70006\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.1642\n",
      "eps  0.07755186682744358 | Reward:  70006\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.4373e-04\n",
      "eps  0.07716410749330636 | Reward:  70007\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.1944e-06\n",
      "eps  0.07677828695583983 | Reward:  70004\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 4.4444e-07\n",
      "eps  0.07639439552106063 | Reward:  70003\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 8.2275e-06\n",
      "eps  0.07601242354345533 | Reward:  70002\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.3380e-05\n",
      "eps  0.07563236142573805 | Reward:  70002\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 2.0660e-08\n",
      "eps  0.07525419961860937 | Reward:  70002\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.4493e-08\n",
      "eps  0.07487792862051632 | Reward:  70002\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.0390e-09\n",
      "eps  0.07450353897741373 | Reward:  70002\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.1601e-09\n",
      "eps  0.07413102128252666 | Reward:  70002\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.7803e-08\n",
      "eps  0.07376036617611402 | Reward:  70002\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.4678e-08\n",
      "eps  0.07339156434523345 | Reward:  70003\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 6.2228e-07\n",
      "eps  0.07302460652350727 | Reward:  70004\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.5241e-07\n",
      "eps  0.07265948349088973 | Reward:  70004\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 3.4877e-08\n",
      "eps  0.07229618607343528 | Reward:  70004\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 3.5524e-06\n",
      "eps  0.0719347051430681 | Reward:  70004\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 2.7162e-08\n",
      "eps  0.07157503161735276 | Reward:  70005\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 5.3712e-07\n",
      "eps  0.071217156459266 | Reward:  70005\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 3.2617e-08\n",
      "eps  0.07086107067696967 | Reward:  70005\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.3093e-08\n",
      "eps  0.07050676532358482 | Reward:  70007\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 4.0761e-07\n",
      "eps  0.0701542314969669 | Reward:  70007\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 4.9707e-08\n",
      "eps  0.06980346033948207 | Reward:  70007\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 5.3454e-08\n",
      "eps  0.06945444303778466 | Reward:  70007\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 2.6361e-08\n",
      "eps  0.06910717082259574 | Reward:  70007\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 4.8101e-08\n",
      "eps  0.06876163496848275 | Reward:  70007\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 2.7173e-08\n",
      "eps  0.06841782679364034 | Reward:  70007\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 3.9746e-08\n",
      "eps  0.06807573765967213 | Reward:  70007\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 3.7644e-08\n",
      "eps  0.06773535897137377 | Reward:  70007\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 4.4509e-08\n",
      "eps  0.0673966821765169 | Reward:  70007\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 2.7699e-08\n",
      "eps  0.0670596987656343 | Reward:  70007\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 5.0620e-08\n",
      "eps  0.06672440027180614 | Reward:  70007\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 4.5450e-08\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eps  0.0663907782704471 | Reward:  70007\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 4.2494e-08\n",
      "eps  0.06605882437909487 | Reward:  70007\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 5.3169e-08\n",
      "eps  0.0657285302571994 | Reward:  70007\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 4.1951e-08\n",
      "eps  0.06539988760591339 | Reward:  70007\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 5.7800e-08\n",
      "eps  0.06507288816788383 | Reward:  70007\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 5.4173e-08\n",
      "eps  0.06474752372704441 | Reward:  70007\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 3.0508e-08\n",
      "eps  0.0644237861084092 | Reward:  70007\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 4.6953e-08\n",
      "eps  0.06410166717786715 | Reward:  70007\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 6.0595e-08\n",
      "eps  0.06378115884197781 | Reward:  70007\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 4.0617e-08\n",
      "eps  0.06346225304776792 | Reward:  70007\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 4.2869e-08\n",
      "eps  0.06314494178252908 | Reward:  70007\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 5.5664e-08\n",
      "eps  0.06282921707361644 | Reward:  70006\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 7.3115e-07\n",
      "eps  0.06251507098824835 | Reward:  70005\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 3.8622e-07\n",
      "eps  0.062202495633307105 | Reward:  70005\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 8.6053e-09\n",
      "eps  0.06189148315514057 | Reward:  70006\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.4277e-05\n",
      "eps  0.061582025739364867 | Reward:  70006\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 2.9621e-08\n",
      "eps  0.06127411561066804 | Reward:  70005\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 2.9759e-07\n",
      "eps  0.0609677450326147 | Reward:  70004\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 4.4880e-07\n",
      "eps  0.06066290630745162 | Reward:  70005\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 5.7295e-06\n",
      "eps  0.060359591775914365 | Reward:  70004\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.0876e-07\n",
      "eps  0.06005779381703479 | Reward:  70005\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 7.0197e-07\n",
      "eps  0.059757504847949616 | Reward:  70005\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 8.5079e-09\n",
      "eps  0.059458717323709866 | Reward:  70005\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 2.2258e-08\n",
      "eps  0.059161423737091316 | Reward:  70005\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.4200e-08\n",
      "eps  0.05886561661840586 | Reward:  70006\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 7.7002e-07\n",
      "eps  0.05857128853531383 | Reward:  70006\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 5.1089e-08\n",
      "eps  0.05827843209263726 | Reward:  70006\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 7.6183e-06\n",
      "eps  0.05798703993217407 | Reward:  70006\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 6.6349e-06\n",
      "eps  0.0576971047325132 | Reward:  70007\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 7.2973e-07\n",
      "eps  0.05740861920885063 | Reward:  70007\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 6.1984e-08\n",
      "eps  0.057121576112806376 | Reward:  70007\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 2.9783e-08\n",
      "eps  0.056835968232242344 | Reward:  70007\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 4.4289e-08\n",
      "eps  0.05655178839108113 | Reward:  70007\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 6.1488e-08\n",
      "eps  0.05626902944912573 | Reward:  70007\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 9.4735e-06\n",
      "eps  0.0559876843018801 | Reward:  80007\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.1770\n",
      "eps  0.055707745880370696 | Reward:  80008\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 7.4312e-07\n",
      "eps  0.05542920715096884 | Reward:  80008\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.3798e-04\n",
      "eps  0.055152061115214 | Reward:  80008\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 3.6874e-08\n",
      "eps  0.05487630080963793 | Reward:  80008\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 6.5314e-08\n",
      "eps  0.05460191930558974 | Reward:  80008\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 6.4939e-08\n",
      "eps  0.05432890970906179 | Reward:  80008\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 4.7231e-08\n",
      "eps  0.05405726516051648 | Reward:  80008\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 5.4525e-08\n",
      "eps  0.0537869788347139 | Reward:  80008\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.1090e-08\n",
      "eps  0.053518043940540334 | Reward:  80008\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 4.7529e-08\n",
      "eps  0.053250453720837636 | Reward:  80008\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.9078e-08\n",
      "eps  0.05298420145223345 | Reward:  80008\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 4.8635e-08\n",
      "eps  0.05271928044497228 | Reward:  80008\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.5572e-08\n",
      "eps  0.05245568404274742 | Reward:  80008\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 4.4152e-08\n",
      "eps  0.05219340562253368 | Reward:  80008\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 1.3384e-06\n",
      "eps  0.05193243859442102 | Reward:  80008\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.4810e-05\n",
      "eps  0.05167277640144891 | Reward:  80008\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 7.6811e-06\n",
      "eps  0.05141441251944167 | Reward:  80005\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 4.4530e-07\n",
      "eps  0.05115734045684446 | Reward:  80004\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.1646\n",
      "eps  0.050901553754560236 | Reward:  80003\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 2.6762e-07\n",
      "eps  0.05064704598578743 | Reward:  80004\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 2.7335e-07\n",
      "eps  0.0503938107558585 | Reward:  80003\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 3.7500e-06\n",
      "eps  0.05014184170207921 | Reward:  80004\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 8.1333e-06\n",
      "eps  0.04989113249356881 | Reward:  80004\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 7.2631e-09\n",
      "eps  0.04964167683110096 | Reward:  80005\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 8.6616e-06\n",
      "eps  0.049393468446945456 | Reward:  80004\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 3.1685e-07\n",
      "eps  0.04914650110471073 | Reward:  60003\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.1539\n",
      "eps  0.048900768599187176 | Reward:  60003\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 7.6816e-06\n",
      "eps  0.04865626475619124 | Reward:  60003\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 2.0875e-08\n",
      "eps  0.04841298343241028 | Reward:  60003\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.8419e-08\n",
      "eps  0.048170918515248226 | Reward:  70003\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 3.2531e-07\n",
      "eps  0.04793006392267198 | Reward:  70004\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4.7109e-07\n",
      "eps  0.047690413603058625 | Reward:  70004\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.9165e-08\n",
      "eps  0.04745196153504333 | Reward:  70004\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.0211e-08\n",
      "eps  0.047214701727368115 | Reward:  70005\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.4515e-07\n",
      "eps  0.04697862821873128 | Reward:  70005\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 3.4560e-08\n",
      "eps  0.04674373507763762 | Reward:  70005\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 3.0333e-08\n",
      "eps  0.04651001640224943 | Reward:  70006\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 4.4048e-07\n",
      "eps  0.04627746632023818 | Reward:  70006\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.7183e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eps  0.04604607898863699 | Reward:  70006\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 4.1528e-08\n",
      "eps  0.0458158485936938 | Reward:  70007\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 6.2772e-07\n",
      "eps  0.04558676935072533 | Reward:  70007\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.4601e-05\n",
      "eps  0.045358835503971705 | Reward:  70007\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 4.5420e-08\n",
      "eps  0.04513204132645185 | Reward:  70007\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 3.3271e-08\n",
      "eps  0.04490638111981959 | Reward:  70007\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 4.6523e-08\n",
      "eps  0.04468184921422049 | Reward:  80007\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 6.4373e-07\n",
      "eps  0.04445843996814939 | Reward:  80008\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 8.9487e-07\n",
      "eps  0.04423614776830864 | Reward:  80008\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 8.3980e-08\n",
      "eps  0.0440149670294671 | Reward:  80008\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 3.8408e-08\n",
      "eps  0.043794892194319764 | Reward:  80008\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 4.1596e-08\n",
      "eps  0.043575917733348166 | Reward:  80008\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 4.6955e-08\n",
      "eps  0.04335803814468143 | Reward:  80008\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 3.9923e-08\n",
      "eps  0.04314124795395802 | Reward:  80008\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 3.2483e-08\n",
      "eps  0.04292554171418823 | Reward:  80008\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 4.1595e-08\n",
      "eps  0.04271091400561729 | Reward:  80008\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 4.7407e-08\n",
      "eps  0.0424973594355892 | Reward:  80008\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 3.8151e-08\n",
      "eps  0.042284872638411256 | Reward:  80008\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 3.5123e-08\n",
      "eps  0.0420734482752192 | Reward:  80006\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 9.5927e-07\n",
      "eps  0.041863081033843105 | Reward:  80006\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 4.2458e-05\n",
      "eps  0.04165376562867389 | Reward:  80005\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 8.9375e-06\n",
      "eps  0.04144549680053052 | Reward:  60004\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 4.0987e-07\n",
      "eps  0.04123826931652787 | Reward:  60005\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 4.7815e-07\n",
      "eps  0.04103207796994523 | Reward:  60005\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 3.1896e-08\n",
      "eps  0.040826917580095504 | Reward:  60005\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 3.9594e-09\n",
      "eps  0.040622782992195024 | Reward:  60006\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 5.9240e-05\n",
      "eps  0.04041966907723405 | Reward:  60005\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1716\n",
      "eps  0.04021757073184788 | Reward:  60006\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 9.4487e-06\n",
      "eps  0.040016482878188646 | Reward:  60006\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 3.5323e-09\n",
      "eps  0.0398164004637977 | Reward:  60006\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 6.9819e-09\n",
      "eps  0.039617318461478715 | Reward:  60006\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 2.1751e-08\n",
      "eps  0.039419231869171324 | Reward:  60006\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 4.6069e-05\n",
      "eps  0.03922213570982547 | Reward:  60006\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 3.4449e-08\n",
      "eps  0.03902602503127634 | Reward:  60006\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 1.8145e-08\n",
      "eps  0.03883089490611996 | Reward:  60006\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 2.1583e-08\n",
      "eps  0.038636740431589364 | Reward:  60006\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.8799e-08\n",
      "eps  0.038443556729431415 | Reward:  60006\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.0803e-08\n",
      "eps  0.03825133894578426 | Reward:  60006\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 2.9805e-08\n",
      "eps  0.03806008225105534 | Reward:  60006\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.6012e-08\n",
      "eps  0.03786978183980006 | Reward:  60006\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 3.8555e-08\n",
      "eps  0.03768043293060106 | Reward:  60006\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 2.9111e-08\n",
      "eps  0.03749203076594806 | Reward:  60006\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 3.1944e-08\n",
      "eps  0.03730457061211832 | Reward:  60006\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 3.3156e-08\n",
      "eps  0.03711804775905773 | Reward:  60006\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 3.0490e-08\n",
      "eps  0.03693245752026244 | Reward:  60006\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 3.5189e-08\n",
      "eps  0.036747795232661126 | Reward:  60006\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.5857e-08\n",
      "eps  0.03656405625649782 | Reward:  60006\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.8050e-08\n",
      "eps  0.03638123597521533 | Reward:  60006\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 2.0260e-08\n",
      "eps  0.036199329795339255 | Reward:  60006\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 2.1495e-08\n",
      "eps  0.03601833314636256 | Reward:  60006\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 2.2556e-08\n",
      "eps  0.03583824148063075 | Reward:  60006\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.9954e-08\n",
      "eps  0.0356590502732276 | Reward:  60006\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 8.6065e-09\n",
      "eps  0.03548075502186146 | Reward:  60006\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 3.7509e-08\n",
      "eps  0.03530335124675215 | Reward:  60006\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 3.0359e-08\n",
      "eps  0.03512683449051839 | Reward:  60006\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 2.8058e-08\n",
      "eps  0.0349512003180658 | Reward:  60006\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 3.3768e-08\n",
      "eps  0.03477644431647547 | Reward:  60006\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 3.0679e-08\n",
      "eps  0.03460256209489309 | Reward:  60006\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.3095e-08\n",
      "eps  0.034429549284418624 | Reward:  60005\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 6.0322e-07\n",
      "eps  0.03425740153799653 | Reward:  60004\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 3.3162e-07\n",
      "eps  0.03408611453030655 | Reward:  60003\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 2.9420e-07\n",
      "eps  0.03391568395765502 | Reward:  60003\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 3.1823e-09\n",
      "eps  0.03374610553786674 | Reward:  60002\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 2.4354e-07\n",
      "eps  0.03357737501017741 | Reward:  60003\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 3.0392e-07\n",
      "eps  0.03340948813512652 | Reward:  60003\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.1082e-09\n",
      "eps  0.03324244069445089 | Reward:  60003\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.1216e-09\n",
      "eps  0.03307622849097864 | Reward:  60003\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.2533e-08\n"
     ]
    }
   ],
   "source": [
    "episodes = 10\n",
    "\n",
    "# RL training\n",
    "#sizes = [12,16,24,32]\n",
    "sizes = [12]\n",
    "\n",
    "BACKUP_RATIO = 10.0 # %\n",
    "\n",
    "for size in sizes:\n",
    "    BASE_FILE_NAME_A = f\"model_ddqn_A_{size}_{episodes}.h5\"\n",
    "    BASE_FILE_NAME_B = f\"model_ddqn_B_{size}_{episodes}.h5\"\n",
    "\n",
    "    # Initialize the model\n",
    "    model_A = get_model(size)\n",
    "    model_B = get_model(size)\n",
    "    \n",
    "    try:\n",
    "        # Change to either final or backup\n",
    "        prefix = \"backup\"\n",
    "        \n",
    "        model_A.load_weights(f\"{prefix}_{BASE_FILE_NAME_A}\", by_name=True, skip_mismatch=True)\n",
    "        model_B.load_weights(f\"{prefix}_{BASE_FILE_NAME_B}\", by_name=True, skip_mismatch=True)\n",
    "        print(\"Weights loaded!\")\n",
    "    except:\n",
    "        print(\"Weights not found...\")\n",
    "        \n",
    "    Last_State = {}\n",
    "    aux_end = aux_start = 0\n",
    "    for eps in range(episodes):\n",
    "        epsilon = 0.2 # Maintaining exploration\n",
    "        clear_output()\n",
    "        \n",
    "        print(f\"Elapsed time: {aux_end - aux_start}\")\n",
    "        \n",
    "        aux_start = time.time()\n",
    "        print(\"=== Episode {} ===\".format(eps))\n",
    "        env = make(\"lux_ai_2021\", debug=True, configuration={\"annotations\": True, \"width\":size, \"height\":size})\n",
    "        steps = env.run([\"simple_agent\", agent])\n",
    "        \n",
    "        aux_end = time.time()\n",
    "        if eps % int(episodes*(BACKUP_RATIO/100)) == 0:\n",
    "            model_A.save_weights(f\"backup_{BASE_FILE_NAME_A}\")\n",
    "            model_B.save_weights(f\"backup_{BASE_FILE_NAME_B}\")\n",
    "        \n",
    "    # Save the models\n",
    "    model_A.save_weights(f\"final_{BASE_FILE_NAME_A}\")\n",
    "    model_B.save_weights(f\"final_{BASE_FILE_NAME_B}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
